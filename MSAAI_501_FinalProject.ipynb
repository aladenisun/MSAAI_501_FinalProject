{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PYTHON LIBRARY SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNiLs4HzKPte"
      },
      "outputs": [],
      "source": [
        "import kagglehub #import module\n",
        "import pandas as pd #import module\n",
        "import os #import module\n",
        "import re #import module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRmfpMFXCO7"
      },
      "source": [
        "### DOWNLOAD AND LOAD DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e7uoSQlAwtLy",
        "outputId": "68402fbf-aa59-4022-9312-7e846e117bde"
      },
      "outputs": [],
      "source": [
        "# Download Dataset\n",
        "path_fake_real = kagglehub.dataset_download(\n",
        "    \"clmentbisaillon/fake-and-real-news-dataset\"\n",
        ")\n",
        "print(\"fake/real path:\", path_fake_real)\n",
        "\n",
        "path_ai1 = kagglehub.dataset_download(\n",
        "    \"walidbenaouda/ai-isot-dataset\"\n",
        ")\n",
        "path_ai2 = kagglehub.dataset_download(\n",
        "    \"atharvasoundankar/gen-ai-misinformation-detection-datase-20242025\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sALHpa3TXXpd"
      },
      "outputs": [],
      "source": [
        "# Load the Fake and True CSV Datasets\n",
        "fake = pd.read_csv(os.path.join(path_fake_real, \"Fake.csv\")) #cvs for fake\n",
        "true = pd.read_csv(os.path.join(path_fake_real, \"True.csv\")) #cvs for true\n",
        "\n",
        "# Load AI Datasets\n",
        "ai_isot = pd.read_csv(os.path.join(path_ai1, \"AI-ISOT dataset.csv\"))\n",
        "ai_gen = pd.read_csv(os.path.join(path_ai2, \"generative_ai_misinformation_dataset.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sEGKUTIJKXm4",
        "outputId": "4a681891-a64c-48e4-aff1-9845eef2ca70"
      },
      "outputs": [],
      "source": [
        "print(f\"-----------------------FAKE.CSV---------------------{fake.head()}\\n\") #shows headers\n",
        "print(f\"-----------------------TRUE.CSV---------------------{true.head()}\\n\") #shows headers\n",
        "print(f\"-----------------------AI_1.CSV----------------------{ai_isot.head()}\\n\")   #shows headers\n",
        "print(f\"-----------------------AI_2.CSV----------------------{ai_gen.head()}\\n\")   #shows headers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJRJaSgJb6iH"
      },
      "source": [
        "### TEXT CLEANING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvcvPt8AeatZ"
      },
      "source": [
        "#### Data Cleaning Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IHmbf4ub_Uv"
      },
      "outputs": [],
      "source": [
        "# Cleaning text in the dataset\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text) # Gets rid of urls\n",
        "    text = re.sub(r\"<.*?>\", \"\", text) # Gets rid of html\n",
        "    text = re.sub(r\"[^a-zA-Z0-9.,!?'â€™\\s]\", \" \", text) # Makes sure punctuation still there\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip() # Fixes spaces\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Pgxlp2cXN9"
      },
      "source": [
        "#### Clean Fake vs True Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KLrI6srNKONT",
        "outputId": "8d7f9c43-184f-4448-c37c-a7417019e0e8"
      },
      "outputs": [],
      "source": [
        "# Clean real vs fake dataset\n",
        "fake[\"is_real\"] = 0 # Gives fake news a label\n",
        "true[\"is_real\"] = 1 # Gives true news a label\n",
        "\n",
        "df_rf = pd.concat([fake, true], ignore_index=True) # Combines datasets\n",
        "\n",
        "# Makes text in one place\n",
        "df_rf[\"text\"] = (\n",
        "    df_rf[\"title\"].fillna(\"\") + \" \" +\n",
        "    df_rf[\"text\"].fillna(\"\")\n",
        ").str.strip()\n",
        "\n",
        "# Gets rid of duplicates and empty text\n",
        "df_rf = df_rf.drop_duplicates(subset=[\"text\"])\n",
        "df_rf = df_rf.dropna(subset=[\"text\"])\n",
        "df_rf = df_rf[df_rf[\"text\"].str.strip() != \"\"]\n",
        "# Cleans the text\n",
        "df_rf[\"text\"] = df_rf[\"text\"].apply(clean_text)\n",
        "\n",
        "# Picks the necessary columns and saves the cleaned file\n",
        "df_rf_clean = df_rf[[\"text\", \"is_real\"]]\n",
        "df_rf_clean[\"source\"] = \"FAKE-REAL\"\n",
        "df_rf_clean.to_csv(\"clean_real_fake.csv\", index=False)\n",
        "\n",
        "# Show it was saved and shows portion of cleaned data set\n",
        "print(\"saved: clean_real_fake.csv\")\n",
        "print(df_rf_clean.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZQ5mFkHcp-f"
      },
      "source": [
        "#### Clean AI vs Human Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9wxRLhrcy1N"
      },
      "source": [
        "##### AI-Dataset 1 - AI-ISOT Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ae6v9nvyhHla",
        "outputId": "bc95b35a-d9ff-4d58-b19a-a9edddd8472f"
      },
      "outputs": [],
      "source": [
        "print(ai_isot.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pWBlqFKYrY-s",
        "outputId": "0a07561d-dd00-4413-cc77-97c88bc21893"
      },
      "outputs": [],
      "source": [
        "ai_isot_long = []\n",
        "\n",
        "# Human-written REAL news : human, real\n",
        "for x in ai_isot[\"Real News\"].dropna():\n",
        "    ai_isot_long.append({\"text\": x, \"is_ai\": 0, \"is_real\": 1})\n",
        "\n",
        "# Human-written FAKE news : human, fake\n",
        "for x in ai_isot[\"Fake News\"].dropna():\n",
        "    ai_isot_long.append({\"text\": x, \"is_ai\": 0, \"is_real\": 0})\n",
        "\n",
        "# AI-generated Fake News : ai, fake\n",
        "for x in ai_isot[\"AI-generated Fake News\"].dropna():\n",
        "    ai_isot_long.append({\"text\": x, \"is_ai\": 1, \"is_real\": 0})\n",
        "\n",
        "ai_isot_df = pd.DataFrame(ai_isot_long)\n",
        "\n",
        "ai_isot_df[\"text\"] = ai_isot_df[\"text\"].apply(clean_text)\n",
        "ai_isot_df[\"source\"] = \"AI-ISOT\"\n",
        "\n",
        "ai_isot_df.to_csv(\"clean_ai_isot.csv\", index=False)\n",
        "print(\"Saved: clean_ai_isot.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe7ciTq5c2rw"
      },
      "source": [
        "##### AI-Dataset 2 - AI_Gen Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CAZWQXT4oEgD",
        "outputId": "b6cebd23-68a6-49a6-ec98-fcc6f0c4427d"
      },
      "outputs": [],
      "source": [
        "print(ai_gen.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jL6VW1ktc6Hz",
        "outputId": "89b9e67f-11a4-4981-aa7c-af7dec357312"
      },
      "outputs": [],
      "source": [
        "# Keep only needed columns\n",
        "ai_gen = ai_gen[[\n",
        "    \"text\", \"is_misinformation\", \"model_signature\",\n",
        "    \"date\", \"month\", \"country\", \"platform\"\n",
        "]]\n",
        "\n",
        "# Drop rows with missing text\n",
        "ai_gen = ai_gen.dropna(subset=[\"text\"])\n",
        "ai_gen = ai_gen[ai_gen[\"text\"].str.strip() != \"\"]\n",
        "\n",
        "# Clean text\n",
        "ai_gen[\"text\"] = ai_gen[\"text\"].apply(clean_text)\n",
        "\n",
        "# Convert model_signature to AI/Human label\n",
        "# 1 = AI-generated, 0 = Human-written\n",
        "ai_gen = ai_gen[ai_gen[\"model_signature\"].isin([\"GPT-like\", \"human\"])]\n",
        "ai_gen[\"is_ai\"] = ai_gen[\"model_signature\"].apply(\n",
        "    lambda x: 1 if x == \"GPT-like\" else 0\n",
        ")\n",
        "\n",
        "# Convert misinformation column to binary label\n",
        "ai_gen[\"is_real\"] = ai_gen[\"is_misinformation\"].apply(\n",
        "    lambda x: 0 if x == 1 else 1\n",
        ")\n",
        "\n",
        "# Final cleaned AI-gen dataset\n",
        "ai_gen_clean = ai_gen[[\n",
        "    \"text\", \"is_real\", \"is_ai\", \"date\", \"month\", \"country\", \"platform\"\n",
        "]]\n",
        "\n",
        "ai_gen_clean.to_csv(\"clean_ai_gen.csv\", index=False)\n",
        "print(\"Saved: clean_ai_gen.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjhH83rMmUbC"
      },
      "source": [
        "#### Combined Master Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udI71UVkmYwz",
        "outputId": "c606d1b3-b722-4a97-a7b0-331ffbe5466d"
      },
      "outputs": [],
      "source": [
        "combined = pd.concat([df_rf_clean, ai_isot_df, ai_gen], ignore_index=True)\n",
        "\n",
        "combined = combined.drop_duplicates(subset=[\"text\"])\n",
        "combined = combined[combined[\"text\"].str.strip() != \"\"]\n",
        "\n",
        "combined.to_csv(\"combined_master_dataset.csv\", index=False)\n",
        "print(\"Saved: combined_master_dataset.csv\")\n",
        "\n",
        "print(\"Rows in final dataset:\", len(combined))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
