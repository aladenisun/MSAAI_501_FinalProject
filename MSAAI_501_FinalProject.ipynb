{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y62UtNwD-fE"
      },
      "source": [
        "### PYTHON LIBRARY SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rpNhlXAiAjNz",
        "outputId": "b14dbb98-1cea-4412-ded3-bfd384892007"
      },
      "outputs": [],
      "source": [
        "# Import the ***TextBlob*** class for sentiment analysis and define a function to extract polarity and subjectivity from text, as specified in the instructions.\n",
        "!pip install textblob\n",
        "!pip install kagglehub\n",
        "!pip install tensorflow\n",
        "!pip install textstat\n",
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNiLs4HzKPte"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import textstat\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "# Import the ***nltk*** library and download the necessary 'stopwords' and 'punkt' corpora for text preprocessing, as specified in the instructions.\n",
        "# This ensures that these resources are available for tokenization and stop word removal.\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, confusion_matrix, precision_recall_curve, average_precision_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Concatenate\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRmfpMFXCO7"
      },
      "source": [
        "### DOWNLOAD AND LOAD DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e7uoSQlAwtLy",
        "outputId": "6e1eebfd-d886-4ee8-db6b-d3dce25f90b7"
      },
      "outputs": [],
      "source": [
        "# Download Dataset\n",
        "path_fake_real = kagglehub.dataset_download(\n",
        "    \"clmentbisaillon/fake-and-real-news-dataset\"\n",
        ")\n",
        "print(\"fake/real path:\", path_fake_real)\n",
        "\n",
        "path_ai1 = kagglehub.dataset_download(\n",
        "    \"walidbenaouda/ai-isot-dataset\"\n",
        ")\n",
        "path_ai2 = kagglehub.dataset_download(\n",
        "    \"atharvasoundankar/gen-ai-misinformation-detection-datase-20242025\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sALHpa3TXXpd"
      },
      "outputs": [],
      "source": [
        "# Load the Fake and True CSV Datasets\n",
        "fake = pd.read_csv(os.path.join(path_fake_real, \"Fake.csv\")) #cvs for fake\n",
        "true = pd.read_csv(os.path.join(path_fake_real, \"True.csv\")) #cvs for true\n",
        "\n",
        "# Load AI Datasets\n",
        "ai_isot = pd.read_csv(os.path.join(path_ai1, \"AI-ISOT dataset.csv\"))\n",
        "ai_gen = pd.read_csv(os.path.join(path_ai2, \"generative_ai_misinformation_dataset.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sEGKUTIJKXm4",
        "outputId": "15d81221-48d8-4edf-e74c-e4f37130b78b"
      },
      "outputs": [],
      "source": [
        "print(f\"-----------------------FAKE.CSV---------------------{fake.head()}\\n\") #shows headers\n",
        "print(f\"-----------------------TRUE.CSV---------------------{true.head()}\\n\") #shows headers\n",
        "print(f\"-----------------------AI_1.CSV----------------------{ai_isot.head()}\\n\")   #shows headers\n",
        "print(f\"-----------------------AI_2.CSV----------------------{ai_gen.head()}\\n\")   #shows headers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJRJaSgJb6iH"
      },
      "source": [
        "### TEXT CLEANING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvcvPt8AeatZ"
      },
      "source": [
        "#### Data Cleaning Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IHmbf4ub_Uv"
      },
      "outputs": [],
      "source": [
        "# Cleaning text in the dataset\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text) # Gets rid of urls\n",
        "    text = re.sub(r\"<.*?>\", \"\", text) # Gets rid of html\n",
        "    text = re.sub(r\"[^a-zA-Z0-9.,!?'â€™\\s]\", \" \", text) # Makes sure punctuation still there\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip() # Fixes spaces\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Pgxlp2cXN9"
      },
      "source": [
        "#### Clean Fake vs True Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KLrI6srNKONT",
        "outputId": "aa2ae915-81bf-4aeb-aaaa-104ff44f7afb"
      },
      "outputs": [],
      "source": [
        "# Clean real vs fake dataset\n",
        "fake[\"is_real\"] = 0 # Gives fake news a label\n",
        "true[\"is_real\"] = 1 # Gives true news a label\n",
        "\n",
        "df_rf = pd.concat([fake, true], ignore_index=True) # Combines datasets\n",
        "\n",
        "# Makes text in one place\n",
        "df_rf[\"text\"] = (\n",
        "    df_rf[\"title\"].fillna(\"\") + \" \" +\n",
        "    df_rf[\"text\"].fillna(\"\")\n",
        ").str.strip()\n",
        "\n",
        "# Gets rid of duplicates and empty text\n",
        "df_rf = df_rf.drop_duplicates(subset=[\"text\"])\n",
        "df_rf = df_rf.dropna(subset=[\"text\"])\n",
        "df_rf = df_rf[df_rf[\"text\"].str.strip() != \"\"]\n",
        "# Cleans the text\n",
        "df_rf[\"text\"] = df_rf[\"text\"].apply(clean_text)\n",
        "\n",
        "# Picks the necessary columns and saves the cleaned file\n",
        "df_rf_clean = df_rf[[\"text\", \"is_real\"]]\n",
        "df_rf_clean[\"source\"] = \"FAKE-REAL\"\n",
        "df_rf_clean.to_csv(\"clean_real_fake.csv\", index=False)\n",
        "\n",
        "# Show it was saved and shows portion of cleaned data set\n",
        "print(\"saved: clean_real_fake.csv\")\n",
        "print(df_rf_clean.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZQ5mFkHcp-f"
      },
      "source": [
        "#### Clean AI vs Human Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9wxRLhrcy1N"
      },
      "source": [
        "##### AI-Dataset 1 - AI-ISOT Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ae6v9nvyhHla",
        "outputId": "b5383878-471c-4cdb-fcfc-2f5b3295f486"
      },
      "outputs": [],
      "source": [
        "print(ai_isot.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pWBlqFKYrY-s",
        "outputId": "7e6a94ff-e3b3-46ab-a89e-b1e8d1fb13b4"
      },
      "outputs": [],
      "source": [
        "ai_isot_long = []\n",
        "\n",
        "# Human-written REAL news : human, real\n",
        "for x in ai_isot[\"Real News\"].dropna():\n",
        "    ai_isot_long.append({\"text\": x, \"is_ai\": 0, \"is_real\": 1})\n",
        "\n",
        "# Human-written FAKE news : human, fake\n",
        "for x in ai_isot[\"Fake News\"].dropna():\n",
        "    ai_isot_long.append({\"text\": x, \"is_ai\": 0, \"is_real\": 0})\n",
        "\n",
        "# AI-generated Fake News : ai, fake\n",
        "for x in ai_isot[\"AI-generated Fake News\"].dropna():\n",
        "    ai_isot_long.append({\"text\": x, \"is_ai\": 1, \"is_real\": 0})\n",
        "\n",
        "ai_isot_df = pd.DataFrame(ai_isot_long)\n",
        "\n",
        "ai_isot_df[\"text\"] = ai_isot_df[\"text\"].apply(clean_text)\n",
        "ai_isot_df[\"source\"] = \"AI-ISOT\"\n",
        "\n",
        "ai_isot_df.to_csv(\"clean_ai_isot.csv\", index=False)\n",
        "print(\"Saved: clean_ai_isot.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe7ciTq5c2rw"
      },
      "source": [
        "##### AI-Dataset 2 - AI_Gen Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CAZWQXT4oEgD",
        "outputId": "baffc4c0-c648-4bc4-cf53-be8a97f5ee37"
      },
      "outputs": [],
      "source": [
        "print(ai_gen.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jL6VW1ktc6Hz",
        "outputId": "5baf9e01-8d75-4205-9f03-0a36d7e863b9"
      },
      "outputs": [],
      "source": [
        "# Keep only needed columns\n",
        "ai_gen = ai_gen[[\n",
        "    \"text\", \"is_misinformation\", \"model_signature\",\n",
        "    \"date\", \"month\", \"country\", \"platform\"\n",
        "]]\n",
        "\n",
        "# Drop rows with missing text\n",
        "ai_gen = ai_gen.dropna(subset=[\"text\"])\n",
        "ai_gen = ai_gen[ai_gen[\"text\"].str.strip() != \"\"]\n",
        "\n",
        "# Clean text\n",
        "ai_gen[\"text\"] = ai_gen[\"text\"].apply(clean_text)\n",
        "\n",
        "# Convert model_signature to AI/Human label\n",
        "# 1 = AI-generated, 0 = Human-written\n",
        "ai_gen = ai_gen[ai_gen[\"model_signature\"].isin([\"GPT-like\", \"human\"])]\n",
        "ai_gen[\"is_ai\"] = ai_gen[\"model_signature\"].apply(\n",
        "    lambda x: 1 if x == \"GPT-like\" else 0\n",
        ")\n",
        "\n",
        "# Convert misinformation column to binary label\n",
        "ai_gen[\"is_real\"] = ai_gen[\"is_misinformation\"].apply(\n",
        "    lambda x: 0 if x == 1 else 1\n",
        ")\n",
        "\n",
        "# Final cleaned AI-gen dataset\n",
        "ai_gen_clean = ai_gen[[\n",
        "    \"text\", \"is_real\", \"is_ai\", \"date\", \"month\", \"country\", \"platform\"\n",
        "]]\n",
        "\n",
        "ai_gen_clean.to_csv(\"clean_ai_gen.csv\", index=False)\n",
        "print(\"Saved: clean_ai_gen.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjhH83rMmUbC"
      },
      "source": [
        "#### Combined Master Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udI71UVkmYwz",
        "outputId": "eae265d9-84b2-41d4-d17d-ffb2aa4698ae"
      },
      "outputs": [],
      "source": [
        "combined = pd.concat([df_rf_clean, ai_isot_df, ai_gen], ignore_index=True)\n",
        "\n",
        "combined = combined.drop_duplicates(subset=[\"text\"])\n",
        "combined = combined[combined[\"text\"].str.strip() != \"\"]\n",
        "\n",
        "combined.to_csv(\"combined_master_dataset.csv\", index=False)\n",
        "print(\"Saved: combined_master_dataset.csv\")\n",
        "\n",
        "print(\"Rows in final dataset:\", len(combined))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8WVaRNwPtwx"
      },
      "source": [
        "#### Combine News Datasets Only for EDA:\n",
        "* df_rf_clean\n",
        "* ai_isot_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p5Gk2OePeEP",
        "outputId": "9e118ada-12bb-4636-b8c0-0fcc9e4bdd63"
      },
      "outputs": [],
      "source": [
        "combined_news = pd.concat([df_rf_clean, ai_isot_df], ignore_index=True)\n",
        "\n",
        "combined_news = combined.drop_duplicates(subset=[\"text\"])\n",
        "combined_news = combined[combined[\"text\"].str.strip() != \"\"]\n",
        "\n",
        "combined_news.to_csv(\"combined_news_dataset.csv\", index=False)\n",
        "print(\"Saved: combined_news_dataset.csv\")\n",
        "\n",
        "print(\"Rows in Combined News Dataset:\", len(combined_news))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "cPOdmV6xS-yD",
        "outputId": "c2788e5f-a03c-4fd3-a555-b5c7514d3a99"
      },
      "outputs": [],
      "source": [
        "combined_news.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a290e164"
      },
      "source": [
        "## EDA\n",
        "Perform an initial data overview of the ***combined_news*** DataFrame by displaying its first few rows, shape, and general information, then analyze and visualize the distribution of the ***is_real*** and ***source*** columns using count plots. Afterwards, handle ***NaN*** values in the ***is_ai*** column by replacing them with -1, and then analyze and visualize its distribution using a count plot. Finally, summarize the key findings from these initial checks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a28d75bc"
      },
      "source": [
        "### 1. Initial Data Overview\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03333b06",
        "outputId": "064067c9-b316-4940-ca81-aa558dfd244f"
      },
      "outputs": [],
      "source": [
        "print(\"First 5 rows of combined_news DataFrame:\")\n",
        "print(combined_news.head())\n",
        "\n",
        "print(\"\\nShape of combined_news DataFrame:\")\n",
        "print(combined_news.shape)\n",
        "\n",
        "print(\"\\nGeneral information about combined_news DataFrame:\")\n",
        "combined_news.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2691f556"
      },
      "source": [
        "### 2. Analyze and visualize the distribution of the ***is_real*** and ***source*** columns using count plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "9c3cf812",
        "outputId": "8efa4aea-73c3-4a88-d526-e969d66c8c2c"
      },
      "outputs": [],
      "source": [
        "color = ['mediumpurple','gold']\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.countplot(data=combined_news, x='is_real', hue='is_real', palette=color, legend = False)\n",
        "plt.title('Distribution of is_real (0=Fake, 1=Real)')\n",
        "plt.xlabel('Is Real')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "c3374c97",
        "outputId": "209f7e26-dec4-4676-e88f-15b94207d203"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=combined_news, x='source', hue='source', palette=color, legend = False)\n",
        "plt.title('Distribution of Source')\n",
        "plt.xlabel('Source')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29be512e"
      },
      "source": [
        "### 3. Handle NaN values in the ***is_ai*** column:\n",
        "Handle `NaN` values in the `is_ai` column by replacing them with -1, and then analyze and visualize its distribution using a count plot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ce35814",
        "outputId": "b97d0903-1768-4860-9728-b1e7705f8437"
      },
      "outputs": [],
      "source": [
        "combined_news['is_ai'] = combined_news['is_ai'].fillna(-1)\n",
        "\n",
        "print(\"Combined_news DataFrame after handling NaN values in 'is_ai':\")\n",
        "print(combined_news.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "collapsed": true,
        "id": "c8b2ca84",
        "outputId": "7435c415-a3c2-41c3-f63d-672966a8f4c8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7, 5))\n",
        "sns.countplot(data=combined_news, x='is_ai', hue='is_ai', palette=color, legend = False)\n",
        "plt.title('Distribution of is_ai (0=Human, 1=AI, -1=Not applicable)')\n",
        "plt.xlabel('Is AI')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bbff525"
      },
      "source": [
        "### 4. Summary of Key Findings\n",
        "\n",
        "**4.1. `combined_news` DataFrame Structure:**\n",
        "*   The DataFrame `combined_news` contains 39,972 entries and 4 columns: `text`, `is_real`, `source`, and `is_ai`.\n",
        "*   The `text`, `is_real`, and `source` columns are fully populated, with no missing values.\n",
        "*   The `is_ai` column initially had a large number of missing (NaN) values, as indicated by only 895 non-null entries before handling.\n",
        "\n",
        "**4.2. Distribution of `is_real`:**\n",
        "*   The count plot for `is_real` shows a fairly balanced distribution between real (1) and fake (0) news entries, which is good for training classification models.\n",
        "\n",
        "**4.3. Distribution of `source`:**\n",
        "*   The `source` column is predominantly composed of entries from \"FAKE-REAL\", with a much smaller proportion from \"AI-ISOT\". This indicates that the dataset is heavily skewed towards traditional fake/real news rather than AI-specific news sources.\n",
        "\n",
        "**4.4. Distribution of `is_ai` after handling NaNs:**\n",
        "*   After replacing `NaN` values with -1, the count plot for `is_ai` clearly shows three categories:\n",
        "    *   `-1` (Not applicable): This is the largest category, representing entries where AI attribution was not originally provided (mostly from the FAKE-REAL dataset).\n",
        "    *   `0` (Human-written): A small number of entries are identified as human-written.\n",
        "    *   `1` (AI-generated): An even smaller number of entries are identified as AI-generated.\n",
        "*   This highlights that the `is_ai` column is largely sparse and mainly applicable to a specific subset of the `combined_news` data (i.e., from the AI-ISOT dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ed9c5b9"
      },
      "source": [
        "### 5. Text Length and Word Count Analysis\n",
        "\n",
        "Calculate the number of characters and words for each text entry in the `combined_news` DataFrame. Visualize the distributions of these metrics using histograms or density plots, and compare the average/median text lengths between real (is_real=1) and fake (is_real=0) news.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42261e3f"
      },
      "source": [
        "First, we will calculate the number of characters for each text entry and store it in a new column ***char_count*** in the ***combined_news*** DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61c6e898",
        "outputId": "fe78269a-ce90-431f-a32d-225d7fcf0f3f"
      },
      "outputs": [],
      "source": [
        "combined_news['char_count'] = combined_news['text'].str.len()\n",
        "print(\"Added 'char_count' column to combined_news DataFrame.\")\n",
        "print(combined_news.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "931897f8"
      },
      "source": [
        "Calculate the number of words for each text entry and store it in a new column ***word_count***.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb1fb361",
        "outputId": "4261d088-3146-4dfb-d19a-f1d3711c49b1"
      },
      "outputs": [],
      "source": [
        "combined_news['word_count'] = combined_news['text'].apply(lambda x: len(str(x).split()))\n",
        "print(\"Added 'word_count' column to combined_news DataFrame.\")\n",
        "print(combined_news.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb7a0765"
      },
      "source": [
        "Visualize the distribution of character count:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "e2e5bb6c",
        "outputId": "fc2d6016-e28c-429a-a7bd-75f27d58abb2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(combined_news['char_count'], bins=50, kde=True, color='mediumpurple')\n",
        "plt.title('Distribution of Character Count')\n",
        "plt.xlabel('Character Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f873578"
      },
      "source": [
        "Visualize the distribution of the ***word_count***.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "a8595635",
        "outputId": "c8bf0083-5075-4a6d-e340-29eb911d69bc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(combined_news['word_count'], bins=50, kde=True, color='gold')\n",
        "plt.title('Distribution of Word Count')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a534241"
      },
      "source": [
        "Calculate the average and median character count for real and fake news articles.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08e47a15",
        "outputId": "c2cede28-2433-4d74-aba9-fcfb23fb2670"
      },
      "outputs": [],
      "source": [
        "print(\"\\nAverage and Median Character Count for Real vs. Fake News:\")\n",
        "print(combined_news.groupby('is_real')['char_count'].agg(['mean', 'median']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab772267"
      },
      "source": [
        "Calculate the average and median word count for real and fake news articles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adb8d2b8",
        "outputId": "064722e7-3a5d-4399-a7ff-8c7760d3fd50"
      },
      "outputs": [],
      "source": [
        "print(\"Average and Median Word Count for Real vs. Fake News:\")\n",
        "print(combined_news.groupby('is_real')['word_count'].agg(['mean', 'median']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb3fb88c"
      },
      "source": [
        "Visually compare the ***char_count*** distribution between real and fake news using a box plot.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "0af1b824",
        "outputId": "49fbf0d9-0da7-4cf4-be2d-18c34d40e744"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(data=combined_news, x='is_real', y='char_count', hue='is_real', palette=['mediumpurple', 'gold'], legend=False)\n",
        "plt.title('Character Count Distribution by News Type (0=Fake, 1=Real)')\n",
        "plt.xlabel('News Type')\n",
        "plt.ylabel('Character Count')\n",
        "plt.xticks([0, 1], ['Fake News', 'Real News'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "846d6a7e"
      },
      "source": [
        "Visually compare the ***word_count*** distribution between real and fake news by creating a box plot.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "3cf2cdaf",
        "outputId": "711544a2-5fc5-4671-884e-387c14836ecb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(data=combined_news, x='is_real', y='word_count', hue='is_real', palette=['mediumpurple', 'gold'], legend=False)\n",
        "plt.title('Word Count Distribution by News Type (0=Fake, 1=Real)')\n",
        "plt.xlabel('News Type')\n",
        "plt.ylabel('Word Count')\n",
        "plt.xticks([0, 1], ['Fake News', 'Real News'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "add1e058"
      },
      "source": [
        "### Summary of Text Length and Word Count Analysis\n",
        "\n",
        "**5.1. Character and Word Counts:**\n",
        "*   New columns ***char_count*** and ***word_count*** were successfully added to the ***combined_news*** DataFrame, providing quantitative metrics for text length.\n",
        "\n",
        "**5.2. Distribution of Text Lengths (Character and Word Counts):**\n",
        "*   Both character and word count distributions show a wide range, indicating variability in article lengths within the dataset. Most articles tend to be shorter, with a long tail extending towards very long articles.\n",
        "*   The distributions appear to be right-skewed, meaning there are many shorter articles and fewer very long ones.\n",
        "\n",
        "**5.3. Comparison of Real vs. Fake News (Character Count):**\n",
        "*   **Average Character Count:** Fake news has a slightly higher average character count (approximately 2551) compared to real news (approximately 2424).\n",
        "*   **Median Character Count:** The medians are very close (2281 for fake, 2265 for real), suggesting that for the majority of articles, the character lengths are quite similar.\n",
        "*   The box plots for character count indicate that fake news tends to have a slightly wider spread and potentially more outliers on the higher end, suggesting some fake news articles can be considerably longer.\n",
        "\n",
        "**5.4. Comparison of Real vs. Fake News (Word Count):**\n",
        "*   **Average Word Count:** Similar to character count, fake news articles have a higher average word count (approximately 434) than real news (approximately 398).\n",
        "*   **Median Word Count:** The medians are also close (390 for fake, 372 for real).\n",
        "*   The box plots for word count also show a similar pattern to character count, with fake news potentially having a slightly larger range and more long-form outliers.\n",
        "\n",
        "**Overall Conclusion:**\n",
        "While there isn't a drastic difference, fake news articles in this combined dataset tend to be slightly longer on average in terms of both character and word counts compared to real news articles. This could be a subtle distinguishing feature, although the distributions largely overlap."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfa5b67a"
      },
      "source": [
        "### 6. Word Frequency and Vocabulary Insights\n",
        "\n",
        "Extract the most frequent words from the 'text' column. Visualize the top 20 most common words across the entire dataset, and then separately for real and fake news using bar charts or word clouds to identify distinctive vocabulary patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "119c235f",
        "outputId": "f5c310f5-d668-48b3-884d-d9555c1149fd"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "print(\"NLTK stopwords and punkt corpora downloaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b53863d"
      },
      "source": [
        "Create a text preprocessing function that converts text to lowercase, tokenizes it, removes stopwords, and filters out non-alphabetic tokens, as described in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef671f1e",
        "outputId": "b6ff4494-055b-487e-ef27-030096d93ba0"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()  # Convert to string and lowercase\n",
        "    tokens = word_tokenize(text) # Tokenize the text\n",
        "    # Remove stop words and non-alphabetic tokens\n",
        "    filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "print(\"Text preprocessing function 'preprocess_text' created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ac43dc0"
      },
      "source": [
        "Now that the preprocessing function is defined, let's apply it to the 'text' column of the ***combined_news*** DataFrame to tokenize and clean the text, storing the result in a new column called 'processed_text'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd31ddf3",
        "outputId": "99a0ec86-d1e8-4b89-a70d-57437ca7fcfa"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt_tab', quiet=True)\n",
        "print(\"NLTK 'punkt_tab' corpus downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9c3cba5",
        "outputId": "ef2a9e3b-510c-4aa4-bcb3-e2300b8e65ac"
      },
      "outputs": [],
      "source": [
        "combined_news['processed_text'] = combined_news['text'].apply(preprocess_text)\n",
        "print(\"Applied 'preprocess_text' to the 'text' column.\")\n",
        "print(combined_news[['text', 'processed_text']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82e2e83e"
      },
      "source": [
        "Now that the text is preprocessed and stored as lists of words in the 'processed_text' column, let's combine all these lists into a single flat list to prepare for counting the most frequent words across the entire dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0101974b",
        "outputId": "fbb792f8-a460-4aef-d0d7-a040b32faf5d"
      },
      "outputs": [],
      "source": [
        "all_words = [word for sublist in combined_news['processed_text'] for word in sublist]\n",
        "print(f\"Total words in the dataset after preprocessing: {len(all_words)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65802b37"
      },
      "source": [
        "Use the ***collections.Counter*** to find the 20 most frequent words, which is a required step for visualizing the top common words across the entire dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a016f8d",
        "outputId": "b9113f0a-c6c9-4584-844a-5168cf101d6d"
      },
      "outputs": [],
      "source": [
        "word_freq = Counter(all_words)\n",
        "top_20_words = word_freq.most_common(20)\n",
        "print(\"Top 20 most common words across the entire dataset:\")\n",
        "print(top_20_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81f91e28"
      },
      "source": [
        "Extract the words and their corresponding frequencies from the ***top_20_words*** list and then use ***matplotlib.pyplot*** and ***seaborn*** to create a bar chart.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "e2403341",
        "outputId": "2cbc2e8e-f6fd-4b05-8b55-d3913acce450"
      },
      "outputs": [],
      "source": [
        "words = [word for word, count in top_20_words]\n",
        "counts = [count for word, count in top_20_words]\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x=words, y=counts, hue=words, palette='viridis', legend=False)\n",
        "plt.title('Top 20 Most Common Words Across All News')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Bar plot of top 20 most common words across the entire dataset displayed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9065ee4e"
      },
      "source": [
        "Filter the ***combined_news*** DataFrame to create a separate DataFrame for real news (where ***is_real*** is 1) to analyze its unique vocabulary patterns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e6883d0",
        "outputId": "7839b442-848a-4ac5-c796-b85339feefb0"
      },
      "outputs": [],
      "source": [
        "real_news_df = combined_news[combined_news['is_real'] == 1]\n",
        "print(\"Filtered real news DataFrame created.\")\n",
        "print(f\"Number of real news entries: {len(real_news_df)}\")\n",
        "print(real_news_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8809690b"
      },
      "source": [
        "Combine all the preprocessed words from the ***processed_text*** column into a single list, which is a necessary step before counting the most frequent words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "099484ee",
        "outputId": "feef9006-1a8e-4c4a-f858-eebdadface5d"
      },
      "outputs": [],
      "source": [
        "real_news_words = [word for sublist in real_news_df['processed_text'] for word in sublist]\n",
        "print(f\"Total words in real news dataset: {len(real_news_words)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31bfa036"
      },
      "source": [
        "Use ***Collections.Counter*** to find the 20 most frequent words specifically for real news.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7654a4d",
        "outputId": "176df95e-6a70-4d1f-e964-14961d9432e1"
      },
      "outputs": [],
      "source": [
        "real_word_freq = Counter(real_news_words)\n",
        "top_20_real_words = real_word_freq.most_common(20)\n",
        "print(\"Top 20 most common words in real news:\")\n",
        "print(top_20_real_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee1cd3ea"
      },
      "source": [
        "To visualize the top 20 most common words in real news, I need to extract the words and their corresponding frequencies from the ***top_20_real_words*** list and then create a bar chart.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "8f87c902",
        "outputId": "9e83fc7b-2cfb-40c5-ac3a-55638744d304"
      },
      "outputs": [],
      "source": [
        "words_real = [word for word, count in top_20_real_words]\n",
        "counts_real = [count for word, count in top_20_real_words]\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x=words_real, y=counts_real, hue=words_real, palette='viridis', legend=False)\n",
        "plt.title('Top 20 Most Common Words in Real News')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Bar plot of top 20 most common words in real news displayed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de69e6e1"
      },
      "source": [
        "Filter the ***combined_news*** DataFrame to create a separate DataFrame for fake news (where ***is_real*** is 0), as specified in the instructions, to analyze its unique vocabulary patterns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3231e6f",
        "outputId": "aead17d7-3e74-41a9-c2b3-6f1774e88c31"
      },
      "outputs": [],
      "source": [
        "fake_news_df = combined_news[combined_news['is_real'] == 0]\n",
        "print(\"Filtered fake news DataFrame created.\")\n",
        "print(f\"Number of fake news entries: {len(fake_news_df)}\")\n",
        "print(fake_news_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71721dd4",
        "outputId": "fa15e8bd-e1ad-4256-add7-da0f55c6a1c5"
      },
      "outputs": [],
      "source": [
        "fake_news_words = [word for sublist in fake_news_df['processed_text'] for word in sublist]\n",
        "print(f\"Total words in fake news dataset: {len(fake_news_words)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbdd1a3d"
      },
      "source": [
        "Now that all processed words from fake news are combined into a single list, let's find the 20 most frequent words specifically for fake news, as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e423ea9",
        "outputId": "6e4d0745-67f1-4a47-8088-247e4abeea02"
      },
      "outputs": [],
      "source": [
        "fake_word_freq = Counter(fake_news_words)\n",
        "top_20_fake_words = fake_word_freq.most_common(20)\n",
        "print(\"Top 20 most common words in fake news:\")\n",
        "print(top_20_fake_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "837206cd"
      },
      "source": [
        "### 7. Sentiment Analysis\n",
        "\n",
        "Perform sentiment analysis on the 'text' column to derive polarity (emotional tone, e.g., positive, negative, neutral) and subjectivity scores. Add these as new columns to the DataFrame and visualize their distributions. Compare the sentiment scores between real and fake news to identify potential differences in emotional content.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "613ae1f2"
      },
      "source": [
        "Define the ***get_sentiment*** function as specified in the instructions to extract polarity and subjectivity scores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ba07984",
        "outputId": "91c2b0f2-fd40-485b-ee76-bfe7b811caa3"
      },
      "outputs": [],
      "source": [
        "def get_sentiment(text):\n",
        "    blob = TextBlob(str(text))\n",
        "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
        "\n",
        "print(\"Imported TextBlob and defined 'get_sentiment' function.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3de699d"
      },
      "source": [
        "Now that the ***get_sentiment*** function is defined, let's apply it to the 'text' column of the ***combined_news*** DataFrame to calculate the polarity and subjectivity scores for each text entry. The results will be stored in new columns named 'polarity' and 'subjectivity' respectively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2246735f",
        "outputId": "7ff5e739-25d5-4058-8b83-06740e1923e3"
      },
      "outputs": [],
      "source": [
        "combined_news[['polarity', 'subjectivity']] = combined_news['text'].apply(lambda x: pd.Series(get_sentiment(x)))\n",
        "print(\"Added 'polarity' and 'subjectivity' columns to combined_news DataFrame.\")\n",
        "print(combined_news.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7a3b79a"
      },
      "source": [
        "Visualize its distribution using a histogram or density plot to understand the overall emotional tone of the news articles.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "40f4eb8b",
        "outputId": "ae628510-2164-4238-c0e3-227a5be9bc96"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(combined_news['polarity'], bins=50, kde=True, color='mediumpurple')\n",
        "plt.title('Distribution of Polarity Scores')\n",
        "plt.xlabel('Polarity Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7541b2f"
      },
      "source": [
        "Now that the 'subjectivity' column has been added to the DataFrame, let's visualize its distribution using a histogram or density plot to understand the degree of factual information versus personal opinions in the news articles.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "418fb1bb",
        "outputId": "8485a2db-4136-4505-d58a-dd4efb02ecbd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(combined_news['subjectivity'], bins=50, kde=True, color='gold')\n",
        "plt.title('Distribution of Subjectivity Scores')\n",
        "plt.xlabel('Subjectivity Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc17dbb6"
      },
      "source": [
        "Compare the average and median polarity scores between real and fake news articles to identify potential differences in emotional tone.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49bb88cf",
        "outputId": "c6e9fc82-ba19-4bdd-e8a3-a792c564331f"
      },
      "outputs": [],
      "source": [
        "print(\"\\nAverage and Median Polarity Scores for Real vs. Fake News:\")\n",
        "print(combined_news.groupby('is_real')['polarity'].agg(['mean', 'median']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f154a45"
      },
      "source": [
        "Compare the average and median subjectivity scores between real and fake news articles to identify potential differences in the degree of factual information versus personal opinions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "492a32cc",
        "outputId": "88e2f5a5-990d-4614-cd76-f575832e66bb"
      },
      "outputs": [],
      "source": [
        "print(\"\\nAverage and Median Subjectivity Scores for Real vs. Fake News:\")\n",
        "print(combined_news.groupby('is_real')['subjectivity'].agg(['mean', 'median']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06be76f7"
      },
      "source": [
        "### Summary of Sentiment Analysis\n",
        "\n",
        "**1. Polarity Scores:**\n",
        "*   The distribution of polarity scores across all news articles is centered around zero, indicating a generally neutral emotional tone, with a slight tendency towards positive sentiment.\n",
        "*   There is a relatively wide spread, suggesting a variety of emotional tones present in the dataset.\n",
        "*   **Comparison (Real vs. Fake News):** Both real and fake news articles exhibit very similar average and median polarity scores, indicating that, on average, their emotional tones are quite close. Fake news has a slightly higher average polarity (approx. 0.0598) than real news (approx. 0.0573), but the difference is marginal.\n",
        "\n",
        "**2. Subjectivity Scores:**\n",
        "*   The distribution of subjectivity scores shows a considerable number of articles leaning towards factual (lower subjectivity) content, but also a significant portion with higher subjectivity, indicating opinion-based writing.\n",
        "*   **Comparison (Real vs. Fake News):** A more notable difference is observed in subjectivity scores. Fake news articles have a significantly higher average subjectivity (approx. 0.4549) and median subjectivity (approx. 0.4552) compared to real news articles (average approx. 0.3624, median approx. 0.3676). This suggests that fake news tends to contain more personal opinions and less factual reporting than real news.\n",
        "\n",
        "**Overall Conclusion:**\n",
        "Sentiment analysis reveals a clearer distinction in subjectivity than in polarity. While both real and fake news exhibit similar emotional tones, fake news articles are generally more subjective, implying a higher presence of opinions, beliefs, and personal feelings compared to the more objective nature of real news. This difference in subjectivity could be a valuable feature for distinguishing between the two news types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41e65839"
      },
      "source": [
        "### Text Analysis Summary:\n",
        "\n",
        "### Key Findings:\n",
        "\n",
        "*   **Text Length Comparison:** Fake news articles tend to be slightly longer than real news articles on average. The average character count for fake news was approximately 2551, while for real news it was around 2424. Similarly, the average word count for fake news was about 434, compared to approximately 398 for real news. However, median lengths were very similar, and distributions largely overlapped, suggesting that while there's a slight tendency, length isn't a strong discriminator on its own.\n",
        "*   **Word Frequency Patterns:**\n",
        "    *   \"Trump\" is a highly frequent word across all news types, appearing as the most common word in fake and overall news, and the second most common in real news.\n",
        "    *   Real news frequently features journalistic terms like \"said\" and source attributions like \"reuters\" (28,861 occurrences in real news).\n",
        "    *   Fake news frequently uses words like \"people,\" \"president,\" \"one,\" \"donald,\" \"like,\" \"obama,\" \"clinton,\" \"video,\" and \"hillary,\" suggesting a focus on specific figures, personal opinions, and potentially sensational content.\n",
        "*   **Sentiment Polarity:** Both real and fake news exhibit very similar emotional tones, with average polarity scores being approximately 0.0573 for real news and 0.0598 for fake news. The distributions for polarity are centered around zero, indicating a generally neutral to slightly positive emotional tone for both categories.\n",
        "*   **Sentiment Subjectivity:** A significant difference was observed in subjectivity. Fake news articles are notably more subjective, with an average subjectivity score of approximately 0.4549 and a median of 0.4552. In contrast, real news articles are more objective, with an average subjectivity score of approximately 0.3624 and a median of 0.3676. This indicates that fake news often contains more opinions and beliefs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtyBEFBN2hWP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mazHuCRiAjN4"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcPutR1oTVvA"
      },
      "source": [
        "### Retrive data for LSTM training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "collapsed": true,
        "id": "G_0jxIatAjN4",
        "outputId": "a3d1922b-b406-494c-a8a6-932411883706"
      },
      "outputs": [],
      "source": [
        "lstm_df = pd.read_csv(\"combined_news_dataset.csv\")\n",
        "\n",
        "print(lstm_df.columns)\n",
        "lstm_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ENkihAn2mHg"
      },
      "source": [
        "### FEATURE ENGINEERING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmmUnzAT2_WE"
      },
      "source": [
        "#### Vocabulary Richness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRJkk8TL2ovc"
      },
      "outputs": [],
      "source": [
        "def vocab_richness(text):\n",
        "    words = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
        "    if len(words) == 0:\n",
        "        return 0\n",
        "    return len(set(words)) / len(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HZvf_s-3IYr"
      },
      "source": [
        "#### Sentiment Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1VVv2Gq3FVX"
      },
      "outputs": [],
      "source": [
        "def sentiment_scores(text):\n",
        "    blob = TextBlob(text)\n",
        "    return blob.sentiment.polarity, blob.sentiment.subjectivity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7XbRUb23QSt"
      },
      "source": [
        "#### Readability Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmGUxeYf3W3j"
      },
      "outputs": [],
      "source": [
        "def readability_score(text):\n",
        "    try:\n",
        "        return textstat.flesch_reading_ease(text)\n",
        "    except:\n",
        "        return np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H4lpeRq3xau"
      },
      "source": [
        "#### Punctuation Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-8HPvYW3w4k"
      },
      "outputs": [],
      "source": [
        "def count_punctuation(text):\n",
        "    return len(re.findall(r\"[.,!?;:]\", text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D09nVx249fyW"
      },
      "source": [
        "#### Average Sentence Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meE85sf89gHs"
      },
      "outputs": [],
      "source": [
        "def avg_sentence_length(text):\n",
        "    sentences = re.split(r\"[.!?]\", text)\n",
        "    sentences = [s.strip() for s in sentences if len(s.strip()) > 0]\n",
        "    if len(sentences) == 0:\n",
        "        return 0\n",
        "    lengths = [len(s.split()) for s in sentences]\n",
        "    return sum(lengths) / len(lengths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTKFdpAm4Fz7"
      },
      "source": [
        "#### Apply Features to the LSTM dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28S3_BUS4KSa"
      },
      "outputs": [],
      "source": [
        "# Vocabulary richness\n",
        "lstm_df[\"vocab_richness\"] = lstm_df[\"text\"].apply(vocab_richness)\n",
        "\n",
        "# Sentiment polarity + subjectivity\n",
        "lstm_df[\"polarity\"], lstm_df[\"subjectivity\"] = zip(*lstm_df[\"text\"].apply(sentiment_scores))\n",
        "\n",
        "# Readability score\n",
        "lstm_df[\"readability\"] = lstm_df[\"text\"].apply(readability_score)\n",
        "\n",
        "# Punctuation\n",
        "lstm_df[\"punctuation_count\"] = lstm_df[\"text\"].apply(count_punctuation)\n",
        "\n",
        "# Average sentence length\n",
        "lstm_df[\"avg_sentence_length\"] = lstm_df[\"text\"].apply(avg_sentence_length)\n",
        "\n",
        "# Save the engineered dataset\n",
        "lstm_df.to_csv(\"combined_with_features.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "collapsed": true,
        "id": "xREPGcCO-9Np",
        "outputId": "c855cdba-0d9b-47c3-d3bb-037c2aec093f"
      },
      "outputs": [],
      "source": [
        "lstm_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3OYWw67Gs19"
      },
      "source": [
        "### Train the Tokenizer on Text and Add Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hamJvNCoBTFV"
      },
      "outputs": [],
      "source": [
        "feature_cols = [\n",
        "    \"vocab_richness\",\n",
        "    \"polarity\",\n",
        "    \"subjectivity\",\n",
        "    \"readability\",\n",
        "    \"punctuation_count\",\n",
        "    \"avg_sentence_length\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKZC-crFAjN4"
      },
      "outputs": [],
      "source": [
        "# Tokenizer converts text to integer tokens based on vocabulary frequency\n",
        "# Take input sequences of sam length, pad short sentences and truncate long sentences.\n",
        "MAX_VOCAB = 30000\n",
        "EMBED_DIMENTION = 128\n",
        "MAX_LEN = 300\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(lstm_df[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPDdhcX2HmH4"
      },
      "source": [
        "### Function to build the LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrTLCRxuDs-M"
      },
      "outputs": [],
      "source": [
        "def make_lstm_model():\n",
        "    # The text input\n",
        "    input_text = Input(shape=(MAX_LEN,), name=\"text_input\")\n",
        "    x = Embedding(MAX_VOCAB, 128, input_length=MAX_LEN)(input_text)\n",
        "    x = LSTM(128)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # The Engineered feature input - 6 features\n",
        "    input_feat = Input(shape=(6,), name=\"feature_input\")\n",
        "    y = Dense(32, activation=\"relu\")(input_feat)\n",
        "    y = Dropout(0.2)(y)\n",
        "\n",
        "    # Combine both text and feature engineer inputs\n",
        "    combined = Concatenate()([x, y])\n",
        "    z = Dense(64, activation=\"relu\")(combined)\n",
        "    z = Dropout(0.2)(z)\n",
        "    output = Dense(1, activation=\"sigmoid\")(z)\n",
        "\n",
        "    model = Model(inputs=[input_text, input_feat], outputs=output)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16mYist9HyHl"
      },
      "source": [
        "### Real vs Fake"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9G27IPWIHir"
      },
      "source": [
        "#### Determine the Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfrvdhkDlvz_"
      },
      "outputs": [],
      "source": [
        "# Convert text to sequences of integers\n",
        "X_features_rf = lstm_df[feature_cols].fillna(0).values\n",
        "sequences_rf = tokenizer.texts_to_sequences(lstm_df[\"text\"])\n",
        "padded_rf = pad_sequences(sequences_rf, maxlen=MAX_LEN, padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqLD1ooKAjN4"
      },
      "outputs": [],
      "source": [
        "X_rf = padded_rf\n",
        "y_rf = lstm_df[\"is_real\"]\n",
        "\n",
        "X_train_rf, X_test_rf, X_feat_train_rf, X_feat_test_rf, y_train_rf, y_test_rf = train_test_split(\n",
        "    X_rf, X_features_rf, y_rf, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SLIk-mbTmqV"
      },
      "source": [
        "#### Build the LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5XIwylXH39h",
        "outputId": "37cb468e-8304-4f43-ec6f-8f1190d6541a"
      },
      "outputs": [],
      "source": [
        "lstm_rf = make_lstm_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOFT2UC0Smvt"
      },
      "source": [
        "#### Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "28GW14zUIFdV",
        "outputId": "164c7862-8571-4409-a90c-237c4b1145fc"
      },
      "outputs": [],
      "source": [
        "history_rf = lstm_rf.fit(\n",
        "    [X_train_rf, X_feat_train_rf],\n",
        "    y_train_rf,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfVv55WmTvNv"
      },
      "source": [
        "#### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psTDcW9_FarA",
        "outputId": "ca19ca16-6245-428a-c61b-b271fbcaae08"
      },
      "outputs": [],
      "source": [
        "lstm_rf.evaluate([X_test_rf, X_feat_test_rf], y_test_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi2yXBypZOo8",
        "outputId": "ba74c1c5-26b0-4507-a9c9-73881f4fb4cf"
      },
      "outputs": [],
      "source": [
        "y_pred = (lstm_rf.predict([X_test_rf, X_feat_test_rf]) > 0.5).astype(int)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test_rf, y_pred))\n",
        "print(classification_report(y_test_rf, y_pred))\n",
        "\n",
        "lstm_rf.save(\"lstm_real_fake_model.keras\")\n",
        "\n",
        "with open(\"lstm_real_fake_tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "print(\"Model and tokenizer saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGMFQvkhojVd"
      },
      "source": [
        "##### Plot Learning Curves (Accuracy and Loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "3XTiJxOsowVw",
        "outputId": "d7c6fb18-d45e-4b51-be73-b18369ce87c6"
      },
      "outputs": [],
      "source": [
        "# Plot the model's accuracy and loss\n",
        "# Create a figure with 1 row and 2 columns\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Accuracy subplot\n",
        "ax1.plot(history_rf.history['accuracy'], label='Training Accuracy')\n",
        "ax1.plot(history_rf.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_title('Model Accuracy')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Loss subplot\n",
        "ax2.plot(history_rf.history['loss'], label='Training Loss')\n",
        "ax2.plot(history_rf.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_title('Model Loss')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "# Display plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S58iXKdI6U72"
      },
      "source": [
        "##### Confusion Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bmuWpG_y6YR2",
        "outputId": "92fa36a8-6be7-431e-c1ab-6699e3725ff1"
      },
      "outputs": [],
      "source": [
        "# Predict probabilities\n",
        "y_pred_probs = lstm_rf.predict([X_test_rf, X_feat_test_rf])\n",
        "\n",
        "# Convert to binary predictions\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TBdDpkfi6jz6",
        "outputId": "88f59f5a-7ab2-40ba-8e13-1c8db19bddb0"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test_rf, y_pred)\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "collapsed": true,
        "id": "uPjf6jkj6m-e",
        "outputId": "88bd6f2c-ad89-4982-e5d3-35fcda945733"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Real\", \"Fake\"],\n",
        "            yticklabels=[\"Real\", \"Fake\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix of Real vs Fake News\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXJXbTKNTfsR"
      },
      "source": [
        "#### SHAP for the Real vs Fake LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpYox7F9nZpm"
      },
      "outputs": [],
      "source": [
        "# Combine X_text and X_features into one 2D matrix\n",
        "X_train_combined = np.hstack([\n",
        "    X_train_rf.reshape(len(X_train_rf), -1),\n",
        "    X_feat_train_rf\n",
        "])\n",
        "\n",
        "X_test_combined = np.hstack([\n",
        "    X_test_rf.reshape(len(X_test_rf), -1),\n",
        "    X_feat_test_rf\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id6Qayjzng-W"
      },
      "outputs": [],
      "source": [
        "# Create background data\n",
        "background_data = X_train_combined[:50]   # 50 samples only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-tq-oWhmZlj"
      },
      "outputs": [],
      "source": [
        "# Define a function for Predictions\n",
        "def model_predict(x):\n",
        "    # Split back into padded text and engineered features\n",
        "    seq_len = X_train_rf.shape[1]\n",
        "\n",
        "    X_seq = x[:, :seq_len].reshape(-1, seq_len)\n",
        "    X_feat = x[:, seq_len:]\n",
        "\n",
        "    return lstm_rf.predict([X_seq, X_feat])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "82ae9e900fe044fe81b50bb099659d3a",
            "243b73d0b1564faab62726bc94f4631f",
            "8063548253d34c7d9d4e537a46fb1e83",
            "7e8ab461a34144d6a7396c53a8a5b7a9",
            "520e333358f646378ecb424e7ce9b3a6",
            "20ce8704aaf444d8bd4cc9343f7b2213",
            "70642cbd616f42399dd049e37d3ce6a1",
            "7984853b5f0a41a8a723bc8b129f8ebc",
            "0d3a9cb4eca9406a850300e27e645bb0",
            "52efe94822574a4a8cdac47cc9600313",
            "9f75480caf774ba881c05483ed787dc2"
          ]
        },
        "id": "GATtPCwsmgJV",
        "outputId": "417b2dc8-cb7b-4a9f-ab51-f8ea6162b1ee"
      },
      "outputs": [],
      "source": [
        "# Build the KernelExplainer\n",
        "explainer_rf = shap.KernelExplainer(model_predict, background_data)\n",
        "\n",
        "# Compute SHAP values on test 3 samples\n",
        "sample_data = X_test_combined[:3]\n",
        "\n",
        "shap_values = explainer_rf.shap_values(sample_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "lhNiyUo_oLry",
        "outputId": "902f55e2-2396-4222-d70f-073243c35187"
      },
      "outputs": [],
      "source": [
        "# Plot SHAP Summary Plot\n",
        "shap.summary_plot(shap_values, sample_data, show=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "yuFE1xzhprJ3",
        "outputId": "5c023f96-e15d-49e8-d370-4a5366e30d5f"
      },
      "outputs": [],
      "source": [
        "y_probs = lstm_rf.predict([X_test_rf, X_feat_test_rf]).flatten()\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test_rf, y_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve for LSTM Real vs Fake Model\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLDcoar0AjN4"
      },
      "source": [
        "### Human vs AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSkaspDIUl07"
      },
      "source": [
        "#### Determine Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "collapsed": true,
        "id": "lc_DXNmqhrgP",
        "outputId": "c19513e9-347f-4948-da90-0fea534199f5"
      },
      "outputs": [],
      "source": [
        "# Clean 'is_ai' labels properly - drop rows where is_ai is NaN\n",
        "df_ai = lstm_df[lstm_df[\"is_ai\"].notna()].copy()\n",
        "\n",
        "print(df_ai[\"is_ai\"].unique())\n",
        "df_ai.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jq7-E8Rxl8yd"
      },
      "outputs": [],
      "source": [
        "# Convert text to sequences of integers\n",
        "sequences_ai = tokenizer.texts_to_sequences(df_ai[\"text\"])\n",
        "padded_ai = pad_sequences(sequences_ai, maxlen=MAX_LEN, padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IyrFxSCS2o3"
      },
      "outputs": [],
      "source": [
        "X_ai = padded_ai\n",
        "\n",
        "# Labels (0 = human, 1 = AI)\n",
        "y_ai = df_ai[\"is_ai\"].astype(int)\n",
        "\n",
        "# Create X_features specifically for the df_ai subset\n",
        "X_features_ai = df_ai[feature_cols].fillna(0).values\n",
        "\n",
        "X_train_ai, X_test_ai, X_feat_train_ai, X_feat_test_ai, y_train_ai, y_test_ai = train_test_split(\n",
        "    X_ai, X_features_ai, y_ai, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOrGhMrYUs3-"
      },
      "source": [
        "#### Build the LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UPOdM-nUfTx"
      },
      "outputs": [],
      "source": [
        "lstm_ai = make_lstm_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTik--3_UyGX"
      },
      "source": [
        "#### Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CQjDrpx1U6RS",
        "outputId": "31943a4f-d645-4c2e-cc6f-43c9b4d88143"
      },
      "outputs": [],
      "source": [
        "history_ai = lstm_ai.fit(\n",
        "    [X_train_ai, X_feat_train_ai],\n",
        "    y_train_ai,\n",
        "    validation_split=0.2,\n",
        "    epochs=15,\n",
        "    batch_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYChdYe7tUPa"
      },
      "source": [
        "#### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vInAXI9UbScN",
        "outputId": "35ab1471-cf5f-4ac9-8d98-8ed410035db5"
      },
      "outputs": [],
      "source": [
        "lstm_ai.evaluate([X_test_ai, X_feat_test_ai], y_test_ai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fdHjfcs0gWeJ",
        "outputId": "ac281408-595c-476c-b104-084b1858ecbd"
      },
      "outputs": [],
      "source": [
        "y_pred = (lstm_ai.predict([X_test_ai, X_feat_test_ai]) > 0.5).astype(int)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test_ai, y_pred))\n",
        "print(classification_report(y_test_ai, y_pred))\n",
        "\n",
        "lstm_ai.save(\"lstm_human_ai_model.keras\")\n",
        "\n",
        "with open(\"lstm_real_fake_tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "print(\"Model and tokenizer saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX9-C4oBpS0B"
      },
      "source": [
        "##### Plot Learning Curves (Accuracy and Loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "collapsed": true,
        "id": "xAwkIUQ3pZpR",
        "outputId": "7850f58b-55af-4392-df22-4a293f1ff0a2"
      },
      "outputs": [],
      "source": [
        "# Plot the model's accuracy and loss\n",
        "# Create a figure with 1 row and 2 columns\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Accuracy subplot\n",
        "ax1.plot(history_ai.history['accuracy'], label='Training Accuracy')\n",
        "ax1.plot(history_ai.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_title('Model Accuracy')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Loss subplot\n",
        "ax2.plot(history_ai.history['loss'], label='Training Loss')\n",
        "ax2.plot(history_ai.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_title('Model Loss')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "# Display plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3WFkOOz41fv"
      },
      "source": [
        "##### Confusion Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXZNqVmp5Ghm",
        "outputId": "4e49cb46-fb14-4e5c-d8e6-3e342eb34f51"
      },
      "outputs": [],
      "source": [
        "# Predict probabilities\n",
        "y_pred_probs = lstm_ai.predict([X_test_ai, X_feat_test_ai])\n",
        "\n",
        "# Convert to binary predictions\n",
        "y_pred_ai = (y_pred_probs > 0.5).astype(int).flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8_Uhrs6W5qHf",
        "outputId": "7c335d06-7c5f-4adf-f4e6-660e63f39a95"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test_ai, y_pred_ai)\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "collapsed": true,
        "id": "eWPFbTpu52SF",
        "outputId": "ec67dbf5-4e56-4b6a-d0f0-c0c0e24c0e12"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"AI\", \"HUM\"],\n",
        "            yticklabels=[\"AI\", \"HUM\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix of AI vs Human Written News\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osdKbRUbUlWh"
      },
      "source": [
        "#### SHAP for the Human vs AI LSTM Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0onXAUNI3ZSs"
      },
      "outputs": [],
      "source": [
        "# Combine X_text and X_features into one 2D matrix\n",
        "X_train_combined = np.hstack([\n",
        "    X_train_ai.reshape(len(X_train_ai), -1),\n",
        "    X_feat_train_ai\n",
        "])\n",
        "\n",
        "X_test_combined = np.hstack([\n",
        "    X_test_ai.reshape(len(X_test_ai), -1),\n",
        "    X_feat_test_ai\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32h6Kknl3ZSs"
      },
      "outputs": [],
      "source": [
        "# Create background data\n",
        "background_data = X_train_combined[:50]   # 50 samples only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WLZLK5H3ZSs"
      },
      "outputs": [],
      "source": [
        "# Define a function for Predictions\n",
        "def model_predict(x):\n",
        "    # Split back into padded text and engineered features\n",
        "    seq_len = X_train_ai.shape[1]\n",
        "\n",
        "    X_seq = x[:, :seq_len].reshape(-1, seq_len)\n",
        "    X_feat = x[:, seq_len:]\n",
        "\n",
        "    return lstm_rf.predict([X_seq, X_feat])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405,
          "referenced_widgets": [
            "49b61084f16744ecabc3694b68155d99",
            "f56da1b26ab04134b80b309c2181963f",
            "51de24f1937d4de9a85fa9d33f0537f2",
            "769b948635c640b69bd9b41f848bb016",
            "c3674e2e7bca43eba368352d4228b32e",
            "a328dfb5e20f4165819ea295994497a3",
            "cca74e86ee844980bbd992fcc062f459",
            "9f745319fac94f7e98dddd99b508ab90",
            "fe99861d80174beb8c10fb4e396e22e6",
            "6cd75cccdfb740598b95ead265a4f88a",
            "8ab3822bb8b447cc9faf863990016ff6"
          ]
        },
        "collapsed": true,
        "id": "zyuaK5Zo3ZSt",
        "outputId": "1d5ed986-ebd4-4ad6-d900-cd0cfae7a307"
      },
      "outputs": [],
      "source": [
        "# Build the KernelExplainer\n",
        "explainer_ai = shap.KernelExplainer(model_predict, background_data)\n",
        "\n",
        "# Compute SHAP values on test 20 samples\n",
        "sample_data = X_test_combined[:3]\n",
        "\n",
        "shap_values = explainer_ai.shap_values(sample_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOFgMxJK3ZSt"
      },
      "outputs": [],
      "source": [
        "# Plot SHAP Summary Plot\n",
        "shap.summary_plot(shap_values, sample_data, show=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcC9leWr3ZSt"
      },
      "outputs": [],
      "source": [
        "y_probs = lstm_ai.predict([X_test_ai, X_feat_test_ai]).flatten()\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test_ai, y_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve for LSTM Real vs Fake Model\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiibENIEVBDJ"
      },
      "source": [
        "### Predict Example Texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8X4EPFjVPjw"
      },
      "outputs": [],
      "source": [
        "example_texts = [\n",
        "    # Realistic real news\n",
        "    \"The government has announced new economic policies today...\",\n",
        "    \"A recent medical study found that exercise reduces stress levels.\",\n",
        "    \"20 million under winter weather alerts as heavy snow blankets parts of the U.S.\",\n",
        "\n",
        "    # Obvious fake / sensational\n",
        "    \"BREAKING: Scientists confirm aliens landed in Nevada last night!!!\",\n",
        "    \"Admiral told lawmakers everyone on alleged drug boat was on a list of military targets\",\n",
        "\n",
        "    # AI-generated style\n",
        "    \"This article was generated by a large language model to simulate political commentary.\",\n",
        "    \"Florida may be Trump's last chance to gain GOP seats through redistricting\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaAiGxUAdPu7"
      },
      "outputs": [],
      "source": [
        "def compute_features(text):\n",
        "    cleaned = clean_text(text)\n",
        "\n",
        "    words = cleaned.split()\n",
        "    vocab_richness = len(set(words)) / (len(words) + 1e-6)\n",
        "\n",
        "    tb = TextBlob(cleaned)\n",
        "    polarity = tb.sentiment.polarity\n",
        "    subjectivity = tb.sentiment.subjectivity\n",
        "\n",
        "    # Additional features used in your training model\n",
        "    exclamation_count = cleaned.count(\"!\")\n",
        "    avg_sentence_length = np.mean([len(s.split()) for s in cleaned.split(\".\") if len(s) > 1])\n",
        "\n",
        "    # Example readability substitute (if Flesch not implemented)\n",
        "    readability = subjectivity  # or replace with your Flesch score\n",
        "\n",
        "    # Return 6 engineered features\n",
        "    return np.array([\n",
        "        vocab_richness,\n",
        "        polarity,\n",
        "        subjectivity,\n",
        "        exclamation_count,\n",
        "        avg_sentence_length,\n",
        "        readability\n",
        "    ], dtype=float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGbBtsMJVN0E"
      },
      "outputs": [],
      "source": [
        "def predict_text(text):\n",
        "    cleaned = clean_text(text)\n",
        "\n",
        "    # Tokenization + Padding\n",
        "    seq = tokenizer.texts_to_sequences([cleaned])\n",
        "    pad = pad_sequences(seq, maxlen=MAX_LEN, padding=\"post\")\n",
        "\n",
        "    # Feature Engineering for This Single Example\n",
        "    feat = compute_features(text)\n",
        "    feat = feat.reshape(1, -1)\n",
        "\n",
        "    # Predictions (now passing both inputs)\n",
        "    pred_realfake = lstm_rf.predict([pad, feat])[0][0]\n",
        "    pred_humanai = lstm_ai.predict([pad, feat])[0][0]\n",
        "\n",
        "    result = {\n",
        "        \"Predicted Real vs Fake\": \"REAL\" if pred_realfake >= 0.5 else \"FAKE\",\n",
        "        \"Confidence (Real)\": float(pred_realfake),\n",
        "        \"Predicted Human vs AI\": \"AI-GENERATED\" if pred_humanai >= 0.5 else \"HUMAN\",\n",
        "        \"Confidence (AI)\": float(pred_humanai)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "OSVlyNvw78Wj",
        "outputId": "d4957c89-0669-4c44-e4c3-62c5e245f7f8"
      },
      "outputs": [],
      "source": [
        "lstm_rf.summary()\n",
        "lstm_ai.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_Sk95e3qnk5l",
        "outputId": "497d0a8e-618b-49ad-ed22-5820b6cd6b07"
      },
      "outputs": [],
      "source": [
        "for text in example_texts:\n",
        "    print(\"\\nTEXT:\", text[:70], \"...\")\n",
        "    predict_text(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGCy5krCpLMO"
      },
      "source": [
        "## LSTM vs Baseline Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNBpA2_-sAlz"
      },
      "source": [
        "Generate predicted probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Cui_yN41c0c",
        "outputId": "51d02798-1a61-4194-ec5c-7bfaa39ef6cf"
      },
      "outputs": [],
      "source": [
        "# Baseline model predictions\n",
        "y_pred_proba_lr = tfidf_grid.predict_proba(X_test)[:, 1]\n",
        "y_pred_lr = (y_pred_proba_lr > 0.5).astype(int)\n",
        "y_pred_lr = tfidf_grid.predict(X_test)\n",
        "\n",
        "# LSTM predictions (Real vs Fake)\n",
        "y_pred_proba_lstm = lstm_rf.predict([X_test_rf, X_feat_test_rf]).flatten()\n",
        "y_pred_lstm = (y_pred_proba_lstm > 0.5).astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97GLiH_G3EyM"
      },
      "source": [
        "Compute ROC curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ka_p2ZHapUql",
        "outputId": "b4e609a9-ec98-433a-beea-12c7e8a10c13"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve(y_true, y_prob, title):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
        "    plt.plot([0,1], [0,1], 'k--')\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Logistic Regression\n",
        "y_prob_lr = tfidf_grid.predict_proba(X_test)[:,1]\n",
        "plot_roc_curve(y_test, y_prob_lr, \"ROC Curve â€“ Logistic Regression\")\n",
        "\n",
        "# LSTM Real vs Fake\n",
        "y_prob_rf = lstm_rf.predict([X_test_rf, X_feat_test_rf]).ravel()\n",
        "plot_roc_curve(y_test_rf, y_prob_rf, \"ROC Curve â€“ LSTM Real vs Fake\")\n",
        "\n",
        "# LSTM Human vs AI\n",
        "y_prob_ai = lstm_ai.predict([X_test_ai, X_feat_test_ai]).ravel()\n",
        "plot_roc_curve(y_test_ai, y_prob_ai, \"ROC Curve â€“ LSTM Human vs AI\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBgW0UxjsKoA"
      },
      "source": [
        "Compute Precision and Recall Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Z3AzGluMsSaH",
        "outputId": "2af44402-a8ec-4c18-fec7-8ba522cabeba"
      },
      "outputs": [],
      "source": [
        "def plot_pr_curve(y_true, y_prob, title):\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
        "    ap = average_precision_score(y_true, y_prob)\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.plot(recall, precision, label=f\"AP = {ap:.3f}\")\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_pr_curve(y_test, y_prob_lr, \"PR Curve â€“ Logistic Regression\")\n",
        "plot_pr_curve(y_test_rf, y_prob_rf, \"PR Curve â€“ LSTM Real vs Fake\")\n",
        "plot_pr_curve(y_test_ai, y_prob_ai, \"PR Curve â€“ LSTM Human vs AI\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydu--_8IsxK0"
      },
      "source": [
        "Model Performance Comparison Chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bG-5jAdK3H0"
      },
      "outputs": [],
      "source": [
        "def get_metrics(y_true, y_pred):\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=\"weighted\"\n",
        "    )\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return acc, precision, recall, f1\n",
        "\n",
        "\n",
        "lr_acc, lr_prec, lr_rec, lr_f1 = get_metrics(y_test, y_pred_lr)\n",
        "lstm_acc, lstm_prec, lstm_rec, lstm_f1 = get_metrics(y_test_rf, y_pred_lstm)\n",
        "\n",
        "metrics = {\n",
        "    \"Model\": [\"Logistic Regression\", \"LSTM\"],\n",
        "    \"Accuracy\": [lr_acc, lstm_acc],\n",
        "    \"Precision\": [lr_prec, lstm_prec],\n",
        "    \"Recall\": [lr_rec, lstm_rec],\n",
        "    \"F1\": [lr_f1, lstm_f1]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "-2P1z7X9sw4s",
        "outputId": "1c266ad2-ac01-42ed-a0c9-1388c2ccb66a"
      },
      "outputs": [],
      "source": [
        "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"]\n",
        "\n",
        "baseline_scores = [\n",
        "    lr_acc, lr_prec, lr_rec, lr_f1\n",
        "]\n",
        "\n",
        "lstm_rf_scores = [\n",
        "    lstm_acc, lstm_prec, lstm_rec, lstm_f1\n",
        "]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.25\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(x - width, baseline_scores, width, label=\"Logistic Regression\")\n",
        "plt.bar(x, lstm_rf_scores, width, label=\"LSTM Real/Fake\")\n",
        "\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.legend()\n",
        "plt.ylim(0, 1.1)\n",
        "plt.grid(axis=\"y\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzuPW6X0ALVA"
      },
      "source": [
        "Generate predicted probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc0w18ciALVA",
        "outputId": "2082ece2-91cd-4cce-a5aa-0fd60c8fe701"
      },
      "outputs": [],
      "source": [
        "# Baseline model predictions\n",
        "y_pred_proba_lr = tfidf_grid.predict_proba(X_test)[:, 1]\n",
        "y_pred_lr = (y_pred_proba_lr > 0.5).astype(int)\n",
        "y_pred_lr = tfidf_grid.predict(X_test)\n",
        "\n",
        "# LSTM predictions (Real vs Fake)\n",
        "y_pred_proba_lstm = lstm_rf.predict([X_test_rf, X_feat_test_rf]).flatten()\n",
        "y_pred_lstm = (y_pred_proba_lstm > 0.5).astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzdBmxCAALVA"
      },
      "source": [
        "Compute ROC curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtsEaquOALVA",
        "outputId": "9f65649c-5d39-43dd-e0a7-8052f55b8a0d"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve(y_true, y_prob, title):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
        "    plt.plot([0,1], [0,1], 'k--')\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Logistic Regression\n",
        "y_prob_lr = tfidf_grid.predict_proba(X_test)[:,1]\n",
        "plot_roc_curve(y_test, y_prob_lr, \"ROC Curve â€“ Logistic Regression\")\n",
        "\n",
        "# LSTM Real vs Fake\n",
        "y_prob_rf = lstm_rf.predict([X_test_rf, X_feat_test_rf]).ravel()\n",
        "plot_roc_curve(y_test_rf, y_prob_rf, \"ROC Curve â€“ LSTM Real vs Fake\")\n",
        "\n",
        "# LSTM Human vs AI\n",
        "y_prob_ai = lstm_ai.predict([X_test_ai, X_feat_test_ai]).ravel()\n",
        "plot_roc_curve(y_test_ai, y_prob_ai, \"ROC Curve â€“ LSTM Human vs AI\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrBz2AJoALVA"
      },
      "source": [
        "Compute Precision and Recall Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSsTKoVTALVA",
        "outputId": "e5654b80-79ce-4e38-8bcf-96d83ca72fd4"
      },
      "outputs": [],
      "source": [
        "def plot_pr_curve(y_true, y_prob, title):\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
        "    ap = average_precision_score(y_true, y_prob)\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.plot(recall, precision, label=f\"AP = {ap:.3f}\")\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_pr_curve(y_test, y_prob_lr, \"PR Curve â€“ Logistic Regression\")\n",
        "plot_pr_curve(y_test_rf, y_prob_rf, \"PR Curve â€“ LSTM Real vs Fake\")\n",
        "plot_pr_curve(y_test_ai, y_prob_ai, \"PR Curve â€“ LSTM Human vs AI\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53x6CtqZALVA"
      },
      "source": [
        "Model Performance Comparison Chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPCnRdNRALVA"
      },
      "outputs": [],
      "source": [
        "def get_metrics(y_true, y_pred):\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=\"weighted\"\n",
        "    )\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return acc, precision, recall, f1\n",
        "\n",
        "\n",
        "lr_acc, lr_prec, lr_rec, lr_f1 = get_metrics(y_test, y_pred_lr)\n",
        "lstm_acc, lstm_prec, lstm_rec, lstm_f1 = get_metrics(y_test_rf, y_pred_lstm)\n",
        "\n",
        "metrics = {\n",
        "    \"Model\": [\"Logistic Regression\", \"LSTM\"],\n",
        "    \"Accuracy\": [lr_acc, lstm_acc],\n",
        "    \"Precision\": [lr_prec, lstm_prec],\n",
        "    \"Recall\": [lr_rec, lstm_rec],\n",
        "    \"F1\": [lr_f1, lstm_f1]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Syf_HFNfALVA",
        "outputId": "45db2cd1-9a3c-4b0b-847e-6d6424df98f4"
      },
      "outputs": [],
      "source": [
        "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"]\n",
        "\n",
        "baseline_scores = [\n",
        "    lr_acc, lr_prec, lr_rec, lr_f1\n",
        "]\n",
        "\n",
        "lstm_rf_scores = [\n",
        "    lstm_acc, lstm_prec, lstm_rec, lstm_f1\n",
        "]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.25\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(x - width, baseline_scores, width, label=\"Logistic Regression\")\n",
        "plt.bar(x, lstm_rf_scores, width, label=\"LSTM Real/Fake\")\n",
        "\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.legend()\n",
        "plt.ylim(0, 1.1)\n",
        "plt.grid(axis=\"y\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7y62UtNwD-fE",
        "yqRmfpMFXCO7",
        "AJRJaSgJb6iH",
        "rvcvPt8AeatZ",
        "q-Pgxlp2cXN9",
        "VZQ5mFkHcp-f",
        "NjhH83rMmUbC",
        "b8WVaRNwPtwx",
        "a290e164",
        "2691f556",
        "29be512e",
        "2ed9c5b9",
        "cfa5b67a",
        "837206cd",
        "mcPutR1oTVvA",
        "-ENkihAn2mHg",
        "pmmUnzAT2_WE",
        "-HZvf_s-3IYr",
        "d7XbRUb23QSt",
        "_H4lpeRq3xau",
        "D09nVx249fyW",
        "dTKFdpAm4Fz7",
        "aPDdhcX2HmH4",
        "16mYist9HyHl",
        "G9G27IPWIHir",
        "_SLIk-mbTmqV",
        "SXJXbTKNTfsR",
        "ZYChdYe7tUPa",
        "XiibENIEVBDJ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.11.14)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d3a9cb4eca9406a850300e27e645bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20ce8704aaf444d8bd4cc9343f7b2213": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243b73d0b1564faab62726bc94f4631f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20ce8704aaf444d8bd4cc9343f7b2213",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_70642cbd616f42399dd049e37d3ce6a1",
            "value": "100%"
          }
        },
        "49b61084f16744ecabc3694b68155d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f56da1b26ab04134b80b309c2181963f",
              "IPY_MODEL_51de24f1937d4de9a85fa9d33f0537f2",
              "IPY_MODEL_769b948635c640b69bd9b41f848bb016"
            ],
            "layout": "IPY_MODEL_c3674e2e7bca43eba368352d4228b32e"
          }
        },
        "51de24f1937d4de9a85fa9d33f0537f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f745319fac94f7e98dddd99b508ab90",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe99861d80174beb8c10fb4e396e22e6",
            "value": 0
          }
        },
        "520e333358f646378ecb424e7ce9b3a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52efe94822574a4a8cdac47cc9600313": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd75cccdfb740598b95ead265a4f88a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70642cbd616f42399dd049e37d3ce6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "769b948635c640b69bd9b41f848bb016": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cd75cccdfb740598b95ead265a4f88a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8ab3822bb8b447cc9faf863990016ff6",
            "value": "â€‡0/3â€‡[01:03&lt;?,â€‡?it/s]"
          }
        },
        "7984853b5f0a41a8a723bc8b129f8ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e8ab461a34144d6a7396c53a8a5b7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52efe94822574a4a8cdac47cc9600313",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9f75480caf774ba881c05483ed787dc2",
            "value": "â€‡3/3â€‡[35:47&lt;00:00,â€‡712.78s/it]"
          }
        },
        "8063548253d34c7d9d4e537a46fb1e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7984853b5f0a41a8a723bc8b129f8ebc",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d3a9cb4eca9406a850300e27e645bb0",
            "value": 3
          }
        },
        "82ae9e900fe044fe81b50bb099659d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_243b73d0b1564faab62726bc94f4631f",
              "IPY_MODEL_8063548253d34c7d9d4e537a46fb1e83",
              "IPY_MODEL_7e8ab461a34144d6a7396c53a8a5b7a9"
            ],
            "layout": "IPY_MODEL_520e333358f646378ecb424e7ce9b3a6"
          }
        },
        "8ab3822bb8b447cc9faf863990016ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f745319fac94f7e98dddd99b508ab90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f75480caf774ba881c05483ed787dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a328dfb5e20f4165819ea295994497a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3674e2e7bca43eba368352d4228b32e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cca74e86ee844980bbd992fcc062f459": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f56da1b26ab04134b80b309c2181963f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a328dfb5e20f4165819ea295994497a3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cca74e86ee844980bbd992fcc062f459",
            "value": "â€‡â€‡0%"
          }
        },
        "fe99861d80174beb8c10fb4e396e22e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
